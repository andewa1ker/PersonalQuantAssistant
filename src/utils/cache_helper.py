"""
ç¼“å­˜è¾…åŠ©å‡½æ•° - æå‡åº”ç”¨æ€§èƒ½
è§£å†³æ•°æ®åŠ è½½ç¼“æ…¢é—®é¢˜
"""
import streamlit as st
from datetime import datetime, timedelta
import pandas as pd
from typing import Optional, Dict, Any, List

# ==================== ä¼šè¯çŠ¶æ€ç®¡ç† ====================

def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'data_cache' not in st.session_state:
        st.session_state.data_cache = {}
    if 'last_update' not in st.session_state:
        st.session_state.last_update = {}
    if 'loading_status' not in st.session_state:
        st.session_state.loading_status = {}

def is_cache_valid(cache_key: str, ttl_seconds: int = 300) -> bool:
    """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
    if cache_key not in st.session_state.last_update:
        return False
    
    last_time = st.session_state.last_update[cache_key]
    elapsed = (datetime.now() - last_time).total_seconds()
    return elapsed < ttl_seconds

def set_cache(cache_key: str, data: Any):
    """è®¾ç½®ç¼“å­˜æ•°æ®"""
    st.session_state.data_cache[cache_key] = data
    st.session_state.last_update[cache_key] = datetime.now()

def get_cache(cache_key: str) -> Optional[Any]:
    """è·å–ç¼“å­˜æ•°æ®"""
    return st.session_state.data_cache.get(cache_key)

def clear_cache(cache_key: Optional[str] = None):
    """æ¸…é™¤ç¼“å­˜"""
    if cache_key:
        st.session_state.data_cache.pop(cache_key, None)
        st.session_state.last_update.pop(cache_key, None)
    else:
        st.session_state.data_cache = {}
        st.session_state.last_update = {}

# ==================== æ•°æ®è·å–è¾…åŠ©å‡½æ•° ====================

@st.cache_data(ttl=300, show_spinner="ğŸ“Š æ­£åœ¨è·å–å®æ—¶æ•°æ®...")
def get_realtime_with_cache(_data_manager, asset_type: str, asset_code: str) -> Optional[Dict]:
    """è·å–å®æ—¶æ•°æ®(å¸¦ç¼“å­˜ 5åˆ†é’Ÿ)"""
    try:
        return _data_manager.get_asset_data(asset_type, asset_code, 'realtime')
    except Exception as e:
        st.warning(f"è·å– {asset_code} å®æ—¶æ•°æ®å¤±è´¥: {str(e)}")
        return None

@st.cache_data(ttl=1800, show_spinner="ğŸ“ˆ æ­£åœ¨è·å–å†å²æ•°æ®...")
def get_history_with_cache(_data_manager, asset_type: str, asset_code: str, period: str = '1y') -> Optional[pd.DataFrame]:
    """è·å–å†å²æ•°æ®(å¸¦ç¼“å­˜ 30åˆ†é’Ÿ)"""
    try:
        return _data_manager.get_asset_data(asset_type, asset_code, 'history', period=period)
    except Exception as e:
        st.warning(f"è·å– {asset_code} å†å²æ•°æ®å¤±è´¥: {str(e)}")
        return None

@st.cache_data(ttl=600, show_spinner="ğŸŒ æ­£åœ¨è·å–å¸‚åœºæ•°æ®...")
def get_market_overview_cache(_data_manager) -> Dict[str, Any]:
    """è·å–å¸‚åœºæ¦‚è§ˆæ•°æ®(å¸¦ç¼“å­˜ 10åˆ†é’Ÿ)"""
    try:
        market_data = {
            'crypto': [],
            'etf': [],
            'stocks': [],
            'timestamp': datetime.now()
        }
        
        # è·å–åŠ å¯†è´§å¸æ•°æ®
        crypto_symbols = ['bitcoin', 'ethereum', 'binancecoin']
        for symbol in crypto_symbols:
            data = get_realtime_with_cache(_data_manager, 'crypto', symbol)
            if data:
                market_data['crypto'].append(data)
        
        # è·å–ETFæ•°æ®
        etf_codes = ['513500', '159915', '512690']
        for code in etf_codes:
            data = get_realtime_with_cache(_data_manager, 'etf', code)
            if data:
                market_data['etf'].append(data)
        
        return market_data
    except Exception as e:
        st.warning(f"è·å–å¸‚åœºæ•°æ®å¤±è´¥: {str(e)}")
        return {'crypto': [], 'etf': [], 'stocks': [], 'timestamp': datetime.now()}

@st.cache_data(ttl=600, show_spinner="ğŸ¯ æ­£åœ¨ç”Ÿæˆäº¤æ˜“ä¿¡å·...")
def get_signals_with_cache(_signal_gen, _data_manager, assets: List[tuple]) -> List[Dict]:
    """è·å–äº¤æ˜“ä¿¡å·(å¸¦ç¼“å­˜ 10åˆ†é’Ÿ)"""
    try:
        signals = []
        for asset_type, asset_code in assets:
            # è·å–å†å²æ•°æ®ç”¨äºä¿¡å·åˆ†æ
            history = get_history_with_cache(_data_manager, asset_type, asset_code, '3m')
            if history is not None and len(history) > 20:
                result = _signal_gen.analyze_with_signals(history, asset_code)
                if result and 'comprehensive_signal' in result:
                    sig = result['comprehensive_signal']
                    signals.append({
                        'asset': asset_code,
                        'type': asset_type,
                        'signal': sig.get('signal', 'è§‚æœ›'),
                        'confidence': sig.get('confidence', 'ä½'),
                        'strength': sig.get('strength', 0),
                        'reasons': sig.get('reasons', [])[:3]  # åªä¿ç•™å‰3æ¡åŸå› 
                    })
        return signals
    except Exception as e:
        st.warning(f"ç”Ÿæˆäº¤æ˜“ä¿¡å·å¤±è´¥: {str(e)}")
        return []

# ==================== æ‰¹é‡æ•°æ®è·å– ====================

def batch_get_realtime(_data_manager, assets: List[tuple], max_concurrent: int = 3) -> Dict[str, Any]:
    """æ‰¹é‡è·å–å®æ—¶æ•°æ®(é™åˆ¶å¹¶å‘æ•°)"""
    results = {}
    for i, (asset_type, asset_code) in enumerate(assets):
        cache_key = f"{asset_type}_{asset_code}_realtime"
        
        # æ£€æŸ¥ä¼šè¯çŠ¶æ€ç¼“å­˜
        if is_cache_valid(cache_key, ttl_seconds=300):
            results[asset_code] = get_cache(cache_key)
        else:
            # æ˜¾ç¤ºåŠ è½½è¿›åº¦
            if i % max_concurrent == 0 and i > 0:
                st.info(f"æ­£åœ¨åŠ è½½ {i}/{len(assets)} ä¸ªèµ„äº§...")
            
            data = get_realtime_with_cache(_data_manager, asset_type, asset_code)
            if data:
                results[asset_code] = data
                set_cache(cache_key, data)
    
    return results

def batch_get_history(_data_manager, assets: List[tuple], period: str = '1y') -> Dict[str, pd.DataFrame]:
    """æ‰¹é‡è·å–å†å²æ•°æ®"""
    results = {}
    total = len(assets)
    
    # åˆ›å»ºè¿›åº¦æ¡
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, (asset_type, asset_code) in enumerate(assets):
        cache_key = f"{asset_type}_{asset_code}_history_{period}"
        
        # æ›´æ–°è¿›åº¦
        progress = (i + 1) / total
        progress_bar.progress(progress)
        status_text.text(f"æ­£åœ¨åŠ è½½ {asset_code} ({i+1}/{total})")
        
        # æ£€æŸ¥ä¼šè¯çŠ¶æ€ç¼“å­˜
        if is_cache_valid(cache_key, ttl_seconds=1800):
            results[asset_code] = get_cache(cache_key)
        else:
            data = get_history_with_cache(_data_manager, asset_type, asset_code, period)
            if data is not None:
                results[asset_code] = data
                set_cache(cache_key, data)
    
    # æ¸…é™¤è¿›åº¦æ˜¾ç¤º
    progress_bar.empty()
    status_text.empty()
    
    return results

# ==================== ç¼“å­˜ç®¡ç†å·¥å…· ====================

def show_cache_manager():
    """æ˜¾ç¤ºç¼“å­˜ç®¡ç†ç•Œé¢"""
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ”„ ç¼“å­˜ç®¡ç†")
    
    # æ˜¾ç¤ºç¼“å­˜çŠ¶æ€
    cache_count = len(st.session_state.get('data_cache', {}))
    st.sidebar.metric("ç¼“å­˜é¡¹æ•°", cache_count)
    
    # æ˜¾ç¤ºæœ€è¿‘æ›´æ–°æ—¶é—´
    if st.session_state.get('last_update'):
        latest_update = max(st.session_state.last_update.values())
        elapsed = (datetime.now() - latest_update).total_seconds()
        st.sidebar.caption(f"æœ€è¿‘æ›´æ–°: {int(elapsed)}ç§’å‰")
    
    # åˆ·æ–°æŒ‰é’®
    col1, col2 = st.sidebar.columns(2)
    with col1:
        if st.button("â™»ï¸ åˆ·æ–°æ•°æ®", use_container_width=True):
            clear_cache()
            st.rerun()
    with col2:
        if st.button("ğŸ—‘ï¸ æ¸…é™¤ç¼“å­˜", use_container_width=True):
            st.cache_data.clear()
            clear_cache()
            st.success("ç¼“å­˜å·²æ¸…é™¤")
            st.rerun()

def get_cache_info() -> Dict[str, Any]:
    """è·å–ç¼“å­˜ä¿¡æ¯"""
    cache_data = st.session_state.get('data_cache', {})
    last_update = st.session_state.get('last_update', {})
    
    info = {
        'total_items': len(cache_data),
        'cache_keys': list(cache_data.keys()),
        'oldest_cache': None,
        'newest_cache': None
    }
    
    if last_update:
        times = list(last_update.values())
        info['oldest_cache'] = min(times)
        info['newest_cache'] = max(times)
    
    return info

# ==================== æ€§èƒ½ç›‘æ§ ====================

def timing_decorator(func_name: str):
    """è®¡æ—¶è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            start = datetime.now()
            result = func(*args, **kwargs)
            elapsed = (datetime.now() - start).total_seconds()
            
            # è®°å½•åˆ°ä¼šè¯çŠ¶æ€
            if 'timing_log' not in st.session_state:
                st.session_state.timing_log = []
            
            st.session_state.timing_log.append({
                'function': func_name,
                'elapsed': elapsed,
                'timestamp': datetime.now()
            })
            
            # åªä¿ç•™æœ€è¿‘100æ¡è®°å½•
            if len(st.session_state.timing_log) > 100:
                st.session_state.timing_log = st.session_state.timing_log[-100:]
            
            return result
        return wrapper
    return decorator

def show_performance_metrics():
    """æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡"""
    if 'timing_log' in st.session_state and st.session_state.timing_log:
        st.sidebar.markdown("### âš¡ æ€§èƒ½æŒ‡æ ‡")
        
        # è®¡ç®—å¹³å‡åŠ è½½æ—¶é—´
        recent_logs = st.session_state.timing_log[-10:]
        avg_time = sum(log['elapsed'] for log in recent_logs) / len(recent_logs)
        
        st.sidebar.metric("å¹³å‡åŠ è½½æ—¶é—´", f"{avg_time:.2f}ç§’")
        
        # æ˜¾ç¤ºæœ€æ…¢çš„æ“ä½œ
        slowest = max(recent_logs, key=lambda x: x['elapsed'])
        st.sidebar.caption(f"æœ€æ…¢: {slowest['function']} ({slowest['elapsed']:.2f}s)")

# ==================== æ™ºèƒ½é¢„åŠ è½½ ====================

def preload_common_data(_data_manager):
    """é¢„åŠ è½½å¸¸ç”¨æ•°æ®"""
    common_assets = [
        ('crypto', 'bitcoin'),
        ('crypto', 'ethereum'),
        ('etf', '513500'),
        ('etf', '159915'),
    ]
    
    # åœ¨åå°é¢„åŠ è½½(ä¸æ˜¾ç¤ºspinner)
    for asset_type, asset_code in common_assets:
        cache_key = f"{asset_type}_{asset_code}_realtime"
        if not is_cache_valid(cache_key, ttl_seconds=300):
            try:
                data = _data_manager.get_asset_data(asset_type, asset_code, 'realtime')
                if data:
                    set_cache(cache_key, data)
            except:
                pass  # é™é»˜å¤±è´¥

# ==================== å¯¼å‡ºå‡½æ•° ====================

__all__ = [
    'init_session_state',
    'get_realtime_with_cache',
    'get_history_with_cache',
    'get_market_overview_cache',
    'get_signals_with_cache',
    'batch_get_realtime',
    'batch_get_history',
    'show_cache_manager',
    'show_performance_metrics',
    'preload_common_data',
    'clear_cache',
    'get_cache_info'
]
