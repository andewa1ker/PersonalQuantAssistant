"""
ç»¼åˆé›†æˆæµ‹è¯• - éªŒè¯æ‰€æœ‰AIæ¨¡å—åŠŸèƒ½
"""

import sys
sys.path.append('.')

import pandas as pd
import numpy as np
from datetime import datetime
from loguru import logger


def generate_test_data(n_days: int = 300) -> pd.DataFrame:
    """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
    dates = pd.date_range(end=datetime.now(), periods=n_days, freq='D')
    
    np.random.seed(42)
    returns = np.random.normal(0.001, 0.02, n_days)
    close = 100 * np.exp(np.cumsum(returns))
    
    high = close * (1 + np.random.uniform(0, 0.02, n_days))
    low = close * (1 - np.random.uniform(0, 0.02, n_days))
    open_price = close * (1 + np.random.normal(0, 0.01, n_days))
    volume = np.random.uniform(1e6, 5e6, n_days)
    
    df = pd.DataFrame({
        'date': dates,
        'open': open_price,
        'high': high,
        'low': low,
        'close': close,
        'volume': volume
    })
    
    df.set_index('date', inplace=True)
    
    return df


def test_ml_predictor():
    """æµ‹è¯•MLé¢„æµ‹å™¨"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•1: MLé¢„æµ‹å™¨")
    logger.info("=" * 60)
    
    from src.ai.ml_predictor import ReturnPredictor, DirectionPredictor
    
    df = generate_test_data(400)
    
    # æµ‹è¯•æ”¶ç›Šç‡é¢„æµ‹
    logger.info("æµ‹è¯•æ”¶ç›Šç‡é¢„æµ‹...")
    return_predictor = ReturnPredictor(forecast_horizon=5)
    training_result = return_predictor.train(df)
    prediction = return_predictor.predict(df)
    
    logger.info(f"  æµ‹è¯•é›†RÂ²: {training_result['test_score']:.4f}")
    logger.info(f"  é¢„æµ‹æ”¶ç›Šç‡: {prediction.prediction:.4f}")
    
    # æµ‹è¯•æ–¹å‘é¢„æµ‹
    logger.info("æµ‹è¯•æ–¹å‘é¢„æµ‹...")
    direction_predictor = DirectionPredictor(forecast_horizon=5)
    training_result = direction_predictor.train(df)
    prediction = direction_predictor.predict(df)
    
    logger.info(f"  æµ‹è¯•é›†RÂ²: {training_result['test_score']:.4f}")
    logger.info(f"  é¢„æµ‹æ–¹å‘: {prediction.prediction:.4f}")
    
    logger.info("âœ… MLé¢„æµ‹å™¨æµ‹è¯•é€šè¿‡")


def test_factor_mining():
    """æµ‹è¯•å› å­æŒ–æ˜"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•2: å› å­æŒ–æ˜")
    logger.info("=" * 60)
    
    from src.ai.factor_mining import FactorMiner, FactorConfig
    
    df = generate_test_data(300)
    
    # åˆ›å»ºç‰¹å¾
    df['returns'] = df['close'].pct_change()
    df['ma_5'] = df['close'].rolling(5).mean()
    df['ma_20'] = df['close'].rolling(20).mean()
    df['volatility'] = df['returns'].rolling(10).std()
    df['forward_returns'] = df['close'].pct_change(5).shift(-5)
    df = df.dropna()
    
    # å› å­æŒ–æ˜
    config = FactorConfig(
        population_size=30,
        generations=5,
        min_ic=0.01
    )
    
    miner = FactorMiner(config)
    result = miner.mine_factors(df, target_column='forward_returns')
    
    logger.info(f"  å‘ç° {len(result.all_factors)} ä¸ªæœ‰æ•ˆå› å­")
    if result.best_factor:
        logger.info(f"  æœ€ä½³å› å­IC: {result.best_factor.ic:.4f}")
    
    logger.info("âœ… å› å­æŒ–æ˜æµ‹è¯•é€šè¿‡")


def test_dl_framework():
    """æµ‹è¯•æ·±åº¦å­¦ä¹ æ¡†æ¶"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•3: æ·±åº¦å­¦ä¹ æ¡†æ¶")
    logger.info("=" * 60)
    
    try:
        from src.ai.dl_framework import DLFramework, DLConfig
        
        df = generate_test_data(200)
        
        # LSTMé…ç½®
        config = DLConfig(
            model_type='lstm',
            sequence_length=30,
            prediction_horizon=5,
            epochs=5,  # å°‘é‡epochç”¨äºæµ‹è¯•
            batch_size=16
        )
        
        framework = DLFramework(config)
        
        X, y = framework.prepare_sequences(df)
        
        logger.info(f"  åºåˆ—å½¢çŠ¶: X={X.shape}, y={y.shape}")
        
        history = framework.train(X, y, validation_split=0.2)
        
        logger.info(f"  è®­ç»ƒå®Œæˆï¼Œæœ€ç»ˆLoss: {history['train_loss'][-1]:.6f}")
        
        # é¢„æµ‹
        last_X = X[-1:]
        prediction = framework.predict(last_X)
        
        logger.info(f"  é¢„æµ‹æ”¶ç›Šç‡: {prediction[0][0]:.4f}")
        
        logger.info("âœ… æ·±åº¦å­¦ä¹ æ¡†æ¶æµ‹è¯•é€šè¿‡")
        
    except ImportError as e:
        logger.warning(f"âš ï¸ PyTorchæœªå®‰è£…ï¼Œè·³è¿‡æ·±åº¦å­¦ä¹ æµ‹è¯•: {e}")
    except Exception as e:
        logger.warning(f"âš ï¸ æ·±åº¦å­¦ä¹ æµ‹è¯•å¤±è´¥: {e}")


def test_nlp_sentiment():
    """æµ‹è¯•NLPæƒ…æ„Ÿåˆ†æ"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•4: NLPæƒ…æ„Ÿåˆ†æ")
    logger.info("=" * 60)
    
    from src.ai.nlp_sentiment import ChineseSentimentAnalyzer, quick_sentiment_analysis
    
    # æµ‹è¯•å•æ–‡æœ¬
    positive_text = "å…¬å¸ä¸šç»©è¶…é¢„æœŸï¼Œå‡€åˆ©æ¶¦å¢é•¿50%ï¼Œæœªæ¥å‘å±•å‰æ™¯è‰¯å¥½"
    negative_text = "è‚¡ä»·å¤§è·Œï¼Œé¢ä¸´é€€å¸‚é£é™©ï¼Œç»è¥çŠ¶å†µæ¶åŒ–"
    
    logger.info("æµ‹è¯•æ­£å‘æ–‡æœ¬...")
    result1 = quick_sentiment_analysis(positive_text)
    logger.info(f"  æƒ…æ„Ÿå¾—åˆ†: {result1['sentiment_score']:.3f}")
    logger.info(f"  æƒ…æ„Ÿæ ‡ç­¾: {result1['sentiment_label']}")
    logger.info(f"  æ­£å‘è¯: {result1['positive_words']}")
    
    logger.info("æµ‹è¯•è´Ÿå‘æ–‡æœ¬...")
    result2 = quick_sentiment_analysis(negative_text)
    logger.info(f"  æƒ…æ„Ÿå¾—åˆ†: {result2['sentiment_score']:.3f}")
    logger.info(f"  æƒ…æ„Ÿæ ‡ç­¾: {result2['sentiment_label']}")
    logger.info(f"  è´Ÿå‘è¯: {result2['negative_words']}")
    
    # æµ‹è¯•æ‰¹é‡åˆ†æ
    logger.info("æµ‹è¯•æ‰¹é‡åˆ†æ...")
    news_list = [
        "å…¬å¸å‘å¸ƒå¹´æŠ¥ï¼Œè¥æ”¶åˆ›å†å²æ–°é«˜",
        "å¸‚åœºé¢„æœŸè‰¯å¥½ï¼Œæœºæ„çœ‹å¥½åå¸‚",
        "å…¬å¸é­é‡é‡å¤§äºæŸï¼Œç®¡ç†å±‚è¾èŒ",
        "æ–°äº§å“ä¸Šå¸‚ï¼Œå¸‚åœºååº”ç§¯æ"
    ]
    
    from src.ai.nlp_sentiment import analyze_news_sentiment
    result_df = analyze_news_sentiment(news_list)
    
    logger.info(f"  æ‰¹é‡åˆ†æå®Œæˆ: {len(result_df)} æ¡")
    logger.info(f"  å¹³å‡æƒ…æ„Ÿå¾—åˆ†: {result_df['sentiment_score'].mean():.3f}")
    
    logger.info("âœ… NLPæƒ…æ„Ÿåˆ†ææµ‹è¯•é€šè¿‡")


def test_integration():
    """é›†æˆæµ‹è¯• - ç«¯åˆ°ç«¯æµç¨‹"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•5: ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•")
    logger.info("=" * 60)
    
    df = generate_test_data(500)
    
    # 1. ç‰¹å¾å·¥ç¨‹
    logger.info("æ­¥éª¤1: ç‰¹å¾å·¥ç¨‹...")
    from src.ai.ml_framework import FeatureEngineer
    
    features = FeatureEngineer.create_technical_features(df)
    features = FeatureEngineer.create_time_features(features)
    
    logger.info(f"  åˆ›å»ºäº† {len(features.columns)} ä¸ªç‰¹å¾")
    
    # 2. MLé¢„æµ‹
    logger.info("æ­¥éª¤2: MLé¢„æµ‹...")
    from src.ai.ml_predictor import ReturnPredictor
    
    predictor = ReturnPredictor(forecast_horizon=5)
    training_result = predictor.train(df)
    prediction = predictor.predict(df)
    
    logger.info(f"  é¢„æµ‹æ”¶ç›Šç‡: {prediction.prediction:.4f}")
    logger.info(f"  é¢„æµ‹ä¿¡å¿ƒ: {prediction.confidence:.4f}" if prediction.confidence else "  æ— é›†æˆ")
    
    # 3. å› å­æŒ–æ˜
    logger.info("æ­¥éª¤3: å› å­æŒ–æ˜...")
    from src.ai.factor_mining import FactorMiner, FactorConfig
    
    features['forward_returns'] = df['close'].pct_change(5).shift(-5)
    features = features.dropna()
    
    config = FactorConfig(
        population_size=20,
        generations=3,
        min_ic=0.01
    )
    
    miner = FactorMiner(config)
    result = miner.mine_factors(features, target_column='forward_returns')
    
    logger.info(f"  å‘ç° {len(result.all_factors)} ä¸ªå› å­")
    
    # 4. æƒ…æ„Ÿåˆ†æ
    logger.info("æ­¥éª¤4: æƒ…æ„Ÿåˆ†æ...")
    from src.ai.nlp_sentiment import quick_sentiment_analysis
    
    sample_news = "å…¬å¸ä¸šç»©è¡¨ç°ä¼˜å¼‚ï¼Œè‚¡ä»·å¼ºåŠ¿ä¸Šæ¶¨ï¼ŒæŠ•èµ„è€…ä¿¡å¿ƒåè¶³"
    sentiment = quick_sentiment_analysis(sample_news)
    
    logger.info(f"  æƒ…æ„Ÿå¾—åˆ†: {sentiment['sentiment_score']:.3f}")
    
    # ç»¼åˆå†³ç­–
    logger.info("\næ­¥éª¤5: ç»¼åˆæŠ•èµ„å†³ç­–...")
    logger.info(f"  MLé¢„æµ‹: {prediction.prediction:.4f}")
    logger.info(f"  æƒ…æ„Ÿå¾—åˆ†: {sentiment['sentiment_score']:.3f}")
    logger.info(f"  å› å­æ•°é‡: {len(result.all_factors)}")
    
    # ç®€å•å†³ç­–é€»è¾‘
    decision_score = (
        prediction.prediction * 0.4 +
        sentiment['sentiment_score'] * 0.3 +
        (len(result.all_factors) / 10) * 0.3
    )
    
    if decision_score > 0.3:
        decision = "ğŸ“ˆ å¼ºçƒˆçœ‹å¤š"
    elif decision_score > 0.1:
        decision = "ğŸ“Š çœ‹å¤š"
    elif decision_score > -0.1:
        decision = "â– ä¸­æ€§"
    elif decision_score > -0.3:
        decision = "ğŸ“‰ çœ‹ç©º"
    else:
        decision = "âš ï¸ å¼ºçƒˆçœ‹ç©º"
    
    logger.info(f"  ç»¼åˆå†³ç­–å¾—åˆ†: {decision_score:.3f}")
    logger.info(f"  æŠ•èµ„å»ºè®®: {decision}")
    
    logger.info("âœ… ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•é€šè¿‡")


def test_ui_pages():
    """æµ‹è¯•UIé¡µé¢å¯¼å…¥"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•6: UIé¡µé¢å¯¼å…¥")
    logger.info("=" * 60)
    
    try:
        from src.ui.ai_prediction_page import show_ai_prediction_page
        logger.info("  âœ“ AIé¢„æµ‹é¡µé¢å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        logger.error(f"  âœ— AIé¢„æµ‹é¡µé¢å¯¼å…¥å¤±è´¥: {e}")
    
    try:
        from src.ui.sentiment_page import show_sentiment_page
        logger.info("  âœ“ æƒ…æ„Ÿåˆ†æé¡µé¢å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        logger.error(f"  âœ— æƒ…æ„Ÿåˆ†æé¡µé¢å¯¼å…¥å¤±è´¥: {e}")
    
    logger.info("âœ… UIé¡µé¢å¯¼å…¥æµ‹è¯•é€šè¿‡")


if __name__ == '__main__':
    logger.info("=" * 60)
    logger.info("PersonalQuantAssistant ç»¼åˆé›†æˆæµ‹è¯•")
    logger.info("=" * 60)
    
    try:
        test_ml_predictor()
        test_factor_mining()
        test_dl_framework()
        test_nlp_sentiment()
        test_integration()
        test_ui_pages()
        
        logger.info("\n" + "=" * 60)
        logger.info("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
