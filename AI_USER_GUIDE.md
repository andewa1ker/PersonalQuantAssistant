# AIæ™ºèƒ½æŠ•èµ„ç³»ç»Ÿ - ç”¨æˆ·ä½¿ç”¨æŒ‡å—

## ğŸ“š ç›®å½•

1. [ç³»ç»Ÿæ¦‚è§ˆ](#ç³»ç»Ÿæ¦‚è§ˆ)
2. [AIé¢„æµ‹æ¨¡å—](#aié¢„æµ‹æ¨¡å—)
3. [å› å­æŒ–æ˜](#å› å­æŒ–æ˜)
4. [æƒ…æ„Ÿåˆ†æ](#æƒ…æ„Ÿåˆ†æ)
5. [æ·±åº¦å­¦ä¹ ](#æ·±åº¦å­¦ä¹ )
6. [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)

---

## ç³»ç»Ÿæ¦‚è§ˆ

PersonalQuantAssistant å·²å‡çº§ä¸ºå®Œæ•´çš„AIé‡åŒ–æŠ•èµ„ç³»ç»Ÿï¼Œé›†æˆäº†ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š

### ğŸ¯ æ ¸å¿ƒAIæ¨¡å—

| æ¨¡å— | åŠŸèƒ½ | æ–‡ä»¶ä½ç½® |
|------|------|----------|
| **MLé¢„æµ‹å™¨** | æ”¶ç›Šç‡/æ–¹å‘/æ³¢åŠ¨ç‡é¢„æµ‹ | `src/ai/ml_predictor.py` |
| **å› å­æŒ–æ˜** | é—ä¼ ç¼–ç¨‹è‡ªåŠ¨å‘ç°Alphaå› å­ | `src/ai/factor_mining.py` |
| **æ·±åº¦å­¦ä¹ ** | LSTM/GRU/Transformeræ—¶åºé¢„æµ‹ | `src/ai/dl_framework.py` |
| **æƒ…æ„Ÿåˆ†æ** | ä¸­æ–‡é‡‘èæ–‡æœ¬æƒ…æ„Ÿè¯†åˆ« | `src/ai/nlp_sentiment.py` |
| **å›æµ‹å¢å¼º** | çœŸå®å¸‚åœºçº¦æŸæ¨¡æ‹Ÿ | `src/strategy/event_driven_backtest.py` |

---

## AIé¢„æµ‹æ¨¡å—

### 1. æ”¶ç›Šç‡é¢„æµ‹ (ReturnPredictor)

**åŠŸèƒ½**: é¢„æµ‹æœªæ¥Nå¤©çš„æ”¶ç›Šç‡

#### ä½¿ç”¨ä»£ç 
```python
from src.ai.ml_predictor import ReturnPredictor
import pandas as pd

# 1. åŠ è½½æ•°æ®ï¼ˆOHLCVæ ¼å¼ï¼‰
data = pd.read_csv("stock_data.csv", parse_dates=['date'])
data.set_index('date', inplace=True)

# 2. åˆ›å»ºé¢„æµ‹å™¨
predictor = ReturnPredictor(
    prediction_days=5,      # é¢„æµ‹5å¤©åæ”¶ç›Šç‡
    model_type='random_forest',  # å¯é€‰: gbdt, ridge, lasso
    use_ensemble=True       # å¯ç”¨é›†æˆå­¦ä¹ 
)

# 3. è®­ç»ƒæ¨¡å‹
predictor.train(data)

# 4. é¢„æµ‹
prediction = predictor.predict(data)
print(f"é¢„æµ‹æ”¶ç›Šç‡: {prediction.value:.2%}")
print(f"é¢„æµ‹ä¿¡å¿ƒ: {prediction.confidence:.2%}")
```

#### ç‰¹å¾å·¥ç¨‹
ç³»ç»Ÿè‡ªåŠ¨åˆ›å»º **31ä¸ªæŠ€æœ¯æŒ‡æ ‡ç‰¹å¾**:
- ç§»åŠ¨å¹³å‡çº¿ (MA): 5/10/20/60æ—¥
- RSI, MACD, å¸ƒæ—å¸¦, ATR
- æˆäº¤é‡æŒ‡æ ‡: OBV, é‡ä»·æ¯”
- æ³¢åŠ¨ç‡: 5/10/20æ—¥
- æ»åç‰¹å¾: 1/2/3/5/10æœŸ

### 2. æ–¹å‘é¢„æµ‹ (DirectionPredictor)

**åŠŸèƒ½**: é¢„æµ‹æ¶¨è·Œæ–¹å‘ï¼ˆä¸Šæ¶¨=1ï¼Œä¸‹è·Œ=-1ï¼‰

```python
from src.ai.ml_predictor import DirectionPredictor

predictor = DirectionPredictor(
    prediction_days=5,
    model_type='random_forest'
)
predictor.train(data)

prediction = predictor.predict(data)
print(f"é¢„æµ‹æ–¹å‘: {'ä¸Šæ¶¨' if prediction.value > 0 else 'ä¸‹è·Œ'}")
print(f"é¢„æµ‹ä¿¡å¿ƒ: {prediction.confidence:.2%}")
```

### 3. æ‰¹é‡é¢„æµ‹ï¼ˆç”¨äºå›æµ‹ï¼‰

```python
# è·å–å†å²é¢„æµ‹åºåˆ—
predictions = predictor.predict_batch(data, start_date='2024-01-01')

# è½¬æ¢ä¸ºDataFrame
pred_df = pd.DataFrame([
    {'date': pred.timestamp, 'value': pred.value, 'confidence': pred.confidence}
    for pred in predictions
])
```

---

## å› å­æŒ–æ˜

### é—ä¼ ç¼–ç¨‹è‡ªåŠ¨å‘ç°Alphaå› å­

**åŸç†**: ä½¿ç”¨é—ä¼ ç®—æ³•è‡ªåŠ¨ç”Ÿæˆå’Œä¼˜åŒ–å› å­è¡¨è¾¾å¼ï¼Œé€šè¿‡ICï¼ˆä¿¡æ¯ç³»æ•°ï¼‰è¯„ä¼°å› å­æœ‰æ•ˆæ€§ã€‚

#### ä½¿ç”¨ä»£ç 
```python
from src.ai.factor_mining import FactorMiner

# 1. åˆ›å»ºæŒ–æ˜å™¨
miner = FactorMiner()

# 2. å‡†å¤‡æ•°æ®ï¼ˆéœ€åŒ…å«returnsåˆ—ï¼‰
data['returns'] = data['close'].pct_change()

# 3. é…ç½®æŒ–æ˜å‚æ•°
config = {
    'population_size': 50,      # ç§ç¾¤å¤§å°
    'generations': 10,           # è¿›åŒ–ä»£æ•°
    'tournament_size': 5,        # é”¦æ ‡èµ›é€‰æ‹©å¤§å°
    'crossover_prob': 0.8,       # äº¤å‰æ¦‚ç‡
    'mutation_prob': 0.2,        # å˜å¼‚æ¦‚ç‡
    'min_ic': 0.02               # æœ€å°ICé˜ˆå€¼
}

# 4. å¼€å§‹æŒ–æ˜
results = miner.mine_factors(data, config)

# 5. æŸ¥çœ‹ç»“æœ
best_factor = results['best_factor']
print(f"æœ€ä½³å› å­è¡¨è¾¾å¼: {best_factor['expression']}")
print(f"IC: {best_factor['ic']:.4f}")
print(f"IC_IR: {best_factor['ic_ir']:.4f}")

# 6. ä½¿ç”¨å› å­é¢„æµ‹
factor_values = best_factor['values']
```

#### ICè¯„ä»·æ ‡å‡†
- **IC > 0.03**: ä¼˜ç§€å› å­
- **IC > 0.02**: è‰¯å¥½å› å­
- **IC > 0.01**: å¯ç”¨å› å­
- **IC_IR > 1.0**: ç¨³å®šæ€§å¥½

#### å› å­è¡¨è¾¾å¼ç¤ºä¾‹
```
æœ€ä½³å› å­: ((high sub low) mul rank(volume))
è§£é‡Š: (æœ€é«˜ä»· - æœ€ä½ä»·) * volumeæ’å
IC: 0.0523, IC_IR: 2.15
```

---

## æƒ…æ„Ÿåˆ†æ

### ä¸­æ–‡é‡‘èæ–‡æœ¬æƒ…æ„Ÿåˆ†æ

**åŠŸèƒ½**: åˆ†æè´¢ç»æ–°é—»ã€å…¬å‘Šã€ç¤¾äº¤åª’ä½“æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ã€‚

#### 1. å•æ–‡æœ¬åˆ†æ

```python
from src.ai.nlp_sentiment import ChineseSentimentAnalyzer

# åˆ›å»ºåˆ†æå™¨
analyzer = ChineseSentimentAnalyzer()

# åˆ†ææ–‡æœ¬
text = "å…¬å¸ä¸šç»©å¤§å¹…å¢é•¿ï¼Œå¸‚åœºå‰æ™¯çœ‹å¥½ï¼ŒæŠ•èµ„ä»·å€¼å‡¸æ˜¾"
result = analyzer.analyze(text)

print(f"æƒ…æ„Ÿå¾—åˆ†: {result['sentiment_score']:.2f}")  # -1åˆ°1
print(f"æƒ…æ„Ÿæ ‡ç­¾: {result['sentiment_label']}")      # positive/negative/neutral
print(f"æ­£å‘è¯: {result['positive_words']}")
print(f"è´Ÿå‘è¯: {result['negative_words']}")
```

#### 2. æ‰¹é‡æ–°é—»åˆ†æ

```python
from src.ai.nlp_sentiment import FinancialSentimentAggregator

# åˆ›å»ºèšåˆå™¨
aggregator = FinancialSentimentAggregator()

# å‡†å¤‡æ–°é—»æ•°æ®
news_list = [
    {'date': '2024-10-01', 'text': 'å…¬å¸ä¸šç»©è¶…é¢„æœŸ...'},
    {'date': '2024-10-02', 'text': 'å¸‚åœºæ‹…å¿§ç»æµæ”¾ç¼“...'},
    {'date': '2024-10-03', 'text': 'æ”¿ç­–åˆ©å¥½å‡ºå°...'}
]

# æ‰¹é‡åˆ†æ
results = aggregator.analyze_batch(news_list)

# æŸ¥çœ‹ç»“æœ
for r in results:
    print(f"{r['date']}: æƒ…æ„Ÿ={r['sentiment']:.2f}, æ ‡ç­¾={r['label']}")
```

#### 3. æƒ…æ„ŸæŒ‡æ•°ï¼ˆ0-100ï¼‰

```python
# è®¡ç®—æ¯æ—¥æƒ…æ„ŸæŒ‡æ•°
sentiment_index = aggregator.calculate_sentiment_index(news_list)

for idx in sentiment_index:
    print(f"{idx['date']}: æŒ‡æ•°={idx['index']:.1f}, ä¿¡å¿ƒ={idx['confidence']:.2%}")

# æŒ‡æ•°è§£è¯»
# 70-100: æåº¦ä¹è§‚ï¼ˆå¼ºçƒˆä¹°å…¥ä¿¡å·ï¼‰
# 60-70:  ä¹è§‚ï¼ˆä¹°å…¥ä¿¡å·ï¼‰
# 40-60:  ä¸­æ€§
# 30-40:  æ‚²è§‚ï¼ˆå–å‡ºä¿¡å·ï¼‰
# 0-30:   æåº¦æ‚²è§‚ï¼ˆå¼ºçƒˆå–å‡ºä¿¡å·ï¼‰
```

#### 4. ç”Ÿæˆäº¤æ˜“ä¿¡å·

```python
signals = aggregator.generate_sentiment_signal(news_list)

for signal in signals:
    print(f"{signal['date']}: {signal['signal']} (å¼ºåº¦={signal['strength']:.2%})")
    print(f"  åŸå› : {signal['reason']}")

# ä¿¡å·ç±»å‹:
# ğŸ”´ å¼ºçƒˆå–å‡º (sentiment < 30 æˆ– çªç„¶ä¸‹é™)
# ğŸŸ¡ å–å‡º (sentiment 30-40)
# âšª æŒæœ‰ (sentiment 40-60)
# ğŸŸ¢ ä¹°å…¥ (sentiment 60-70)
# ğŸ”µ å¼ºçƒˆä¹°å…¥ (sentiment > 70 æˆ– çªç„¶ä¸Šå‡)
```

---

## æ·±åº¦å­¦ä¹ 

### LSTM/GRU/Transformer æ—¶åºé¢„æµ‹

**ä¾èµ–**: éœ€è¦å®‰è£… PyTorch
```bash
pip install torch
```

#### 1. LSTMé¢„æµ‹

```python
from src.ai.dl_framework import DLFramework

# åˆ›å»ºæ¡†æ¶
framework = DLFramework(
    model_type='lstm',
    input_size=5,           # è¾“å…¥ç‰¹å¾æ•°ï¼ˆOHLCVï¼‰
    hidden_size=64,         # éšè—å±‚å¤§å°
    num_layers=2,           # LSTMå±‚æ•°
    dropout=0.2,            # Dropoutæ¯”ä¾‹
    learning_rate=0.001
)

# å‡†å¤‡åºåˆ—æ•°æ®
X, y = framework.prepare_sequence_data(
    data[['open', 'high', 'low', 'close', 'volume']],
    target=data['close'].shift(-1),  # é¢„æµ‹ä¸‹ä¸€ä¸ªæ”¶ç›˜ä»·
    sequence_length=20               # ä½¿ç”¨20å¤©å†å²
)

# è®­ç»ƒæ¨¡å‹
history = framework.train(
    X, y,
    epochs=50,
    batch_size=32,
    validation_split=0.2,
    early_stopping=True,    # å¯ç”¨æ—©åœ
    patience=10
)

# é¢„æµ‹
predictions = framework.predict(X[-1:])
print(f"é¢„æµ‹ä¸‹ä¸€ä¸ªæ”¶ç›˜ä»·: {predictions[0][0]:.2f}")
```

#### 2. Transformeré¢„æµ‹

```python
# åˆ›å»ºTransformeræ¨¡å‹
framework = DLFramework(
    model_type='transformer',
    input_size=5,
    hidden_size=128,
    num_layers=3,
    num_heads=4,            # å¤šå¤´æ³¨æ„åŠ›å¤´æ•°
    dropout=0.1
)

# è®­ç»ƒå’Œé¢„æµ‹æµç¨‹ç›¸åŒ
framework.train(X, y, epochs=50)
predictions = framework.predict(X[-1:])
```

#### 3. å¿«é€ŸLSTMé¢„æµ‹ï¼ˆä¸€è¡Œä»£ç ï¼‰

```python
from src.ai.dl_framework import quick_lstm_predict

predictions = quick_lstm_predict(
    data=data[['close']],
    epochs=30,
    sequence_length=20
)
```

---

## ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´æŠ•èµ„å†³ç­–æµç¨‹

```python
import pandas as pd
from src.ai.ml_predictor import ReturnPredictor, DirectionPredictor
from src.ai.factor_mining import FactorMiner
from src.ai.nlp_sentiment import FinancialSentimentAggregator

# ========== 1. åŠ è½½æ•°æ® ==========
stock_data = pd.read_csv("stock.csv", parse_dates=['date'])
stock_data.set_index('date', inplace=True)
stock_data['returns'] = stock_data['close'].pct_change()

news_data = pd.read_csv("news.csv", parse_dates=['date'])

# ========== 2. MLé¢„æµ‹ ==========
return_pred = ReturnPredictor(prediction_days=5, use_ensemble=True)
return_pred.train(stock_data)
ml_prediction = return_pred.predict(stock_data)

print(f"\nğŸ“Š MLé¢„æµ‹:")
print(f"  é¢„æµ‹æ”¶ç›Šç‡: {ml_prediction.value:.2%}")
print(f"  é¢„æµ‹ä¿¡å¿ƒ: {ml_prediction.confidence:.2%}")

# ========== 3. å› å­æŒ–æ˜ ==========
miner = FactorMiner()
factors = miner.mine_factors(stock_data, {
    'population_size': 50,
    'generations': 10,
    'min_ic': 0.02
})

print(f"\nğŸ” å› å­æŒ–æ˜:")
print(f"  å‘ç° {len(factors['factors'])} ä¸ªæœ‰æ•ˆå› å­")
print(f"  æœ€ä½³IC: {factors['best_factor']['ic']:.4f}")

# ========== 4. æƒ…æ„Ÿåˆ†æ ==========
aggregator = FinancialSentimentAggregator()
sentiment = aggregator.calculate_sentiment_index(news_data.to_dict('records'))

latest_sentiment = sentiment[-1] if sentiment else {'index': 50}
print(f"\nğŸ’¬ æƒ…æ„Ÿåˆ†æ:")
print(f"  æƒ…æ„ŸæŒ‡æ•°: {latest_sentiment['index']:.1f}/100")

# ========== 5. ç»¼åˆå†³ç­– ==========
ml_score = ml_prediction.value * ml_prediction.confidence
factor_score = factors['best_factor']['ic'] if factors['factors'] else 0
sentiment_score = (latest_sentiment['index'] - 50) / 50  # å½’ä¸€åŒ–åˆ°-1åˆ°1

# åŠ æƒç»¼åˆï¼ˆå¯è°ƒæ•´æƒé‡ï¼‰
final_score = (
    0.4 * ml_score +
    0.3 * sentiment_score +
    0.3 * factor_score
)

print(f"\nğŸ¯ ç»¼åˆæŠ•èµ„å†³ç­–:")
print(f"  MLè´¡çŒ®: {ml_score:.3f} (æƒé‡40%)")
print(f"  æƒ…æ„Ÿè´¡çŒ®: {sentiment_score:.3f} (æƒé‡30%)")
print(f"  å› å­è´¡çŒ®: {factor_score:.3f} (æƒé‡30%)")
print(f"  æœ€ç»ˆå¾—åˆ†: {final_score:.3f}")

# ç”Ÿæˆå»ºè®®
if final_score > 0.2:
    decision = "ğŸ”µ å¼ºçƒˆä¹°å…¥"
elif final_score > 0.05:
    decision = "ğŸŸ¢ ä¹°å…¥"
elif final_score > -0.05:
    decision = "â– ä¸­æ€§"
elif final_score > -0.2:
    decision = "ğŸŸ¡ å–å‡º"
else:
    decision = "ğŸ”´ å¼ºçƒˆå–å‡º"

print(f"  æŠ•èµ„å»ºè®®: {decision}")
```

---

## UIç•Œé¢ä½¿ç”¨

### å¯åŠ¨ç³»ç»Ÿ
```bash
cd PersonalQuantAssistant
streamlit run main.py
```

### AIé¢„æµ‹é¡µé¢

1. **å·¦ä¾§èœå•** â†’ é€‰æ‹© "ğŸ¤– AIæ™ºèƒ½é¢„æµ‹"

2. **å››ä¸ªæ ‡ç­¾é¡µ**:
   - **æ”¶ç›Šç‡é¢„æµ‹**: è¾“å…¥è‚¡ç¥¨ä»£ç ï¼Œé€‰æ‹©é¢„æµ‹å¤©æ•°ï¼ŒæŸ¥çœ‹é¢„æµ‹æ”¶ç›Šç‡å’Œä¿¡å¿ƒåº¦
   - **æ–¹å‘é¢„æµ‹**: é¢„æµ‹æ¶¨è·Œæ–¹å‘ï¼Œæ˜¾ç¤ºå‡†ç¡®ç‡å’Œæ··æ·†çŸ©é˜µ
   - **å› å­æŒ–æ˜**: é…ç½®é—ä¼ ç®—æ³•å‚æ•°ï¼ŒæŸ¥çœ‹å› å­è¿›åŒ–è¿‡ç¨‹å’Œæœ€ä½³å› å­
   - **æ¨¡å‹å¯¹æ¯”**: å¯¹æ¯”Random Forestã€GBDTã€Ridgeç­‰æ¨¡å‹æ€§èƒ½

### æƒ…æ„Ÿåˆ†æé¡µé¢

1. **å·¦ä¾§èœå•** â†’ é€‰æ‹© "ğŸ’¬ æƒ…æ„Ÿåˆ†æ"

2. **å››ä¸ªæ ‡ç­¾é¡µ**:
   - **å•æ–‡æœ¬åˆ†æ**: è¾“å…¥æ–‡æœ¬ï¼ŒæŸ¥çœ‹æƒ…æ„Ÿå¾—åˆ†å’Œå…³é”®è¯
   - **æ‰¹é‡æ–°é—»åˆ†æ**: ä¸Šä¼ CSVæ–‡ä»¶ï¼Œæ‰¹é‡åˆ†ææ–°é—»æƒ…æ„Ÿ
   - **æƒ…æ„ŸæŒ‡æ•°**: æŸ¥çœ‹æ¯æ—¥æƒ…æ„ŸæŒ‡æ•°æ—¶é—´åºåˆ—
   - **äº¤æ˜“ä¿¡å·**: åŸºäºæƒ…æ„Ÿå˜åŒ–ç”Ÿæˆä¹°å–ä¿¡å·

---

## æ•°æ®æ ¼å¼è¦æ±‚

### è‚¡ç¥¨æ•°æ®æ ¼å¼
```csv
date,open,high,low,close,volume
2024-01-01,100.5,102.3,99.8,101.2,1500000
2024-01-02,101.5,103.1,101.0,102.5,1800000
...
```

### æ–°é—»æ•°æ®æ ¼å¼
```csv
date,text
2024-01-01,å…¬å¸å‘å¸ƒQ4è´¢æŠ¥ï¼Œè¥æ”¶åŒæ¯”å¢é•¿25%...
2024-01-02,å¸‚åœºæ‹…å¿§ç¾è”å‚¨åŠ æ¯...
...
```

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. MLæ¨¡å‹é€‰æ‹©
- **Random Forest**: å¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦ï¼Œé»˜è®¤æ¨è
- **GBDT**: ç²¾åº¦æœ€é«˜ï¼Œè®­ç»ƒæ—¶é—´è¾ƒé•¿
- **Ridge/Lasso**: é€Ÿåº¦æœ€å¿«ï¼Œé€‚åˆå¿«é€Ÿè¿­ä»£

### 2. å› å­æŒ–æ˜å‚æ•°
- **å°æ•°æ®é›†** (<1000æ¡): population=30, generations=5
- **ä¸­ç­‰æ•°æ®é›†** (1000-5000): population=50, generations=10
- **å¤§æ•°æ®é›†** (>5000): population=100, generations=20

### 3. æ·±åº¦å­¦ä¹ å‚æ•°
- **LSTM**: é€‚åˆé•¿æœŸä¾èµ–ï¼Œsequence_length=20-60
- **GRU**: é€Ÿåº¦æ›´å¿«ï¼Œæ€§èƒ½æ¥è¿‘LSTM
- **Transformer**: æœ€å…ˆè¿›ï¼Œä½†éœ€è¦æ›´å¤šæ•°æ®ï¼ˆ>5000æ¡ï¼‰

---

## å¸¸è§é—®é¢˜

### Q1: é¢„æµ‹å‡†ç¡®ç‡ä¸é«˜æ€ä¹ˆåŠï¼Ÿ
**A**: 
1. å¢åŠ è®­ç»ƒæ•°æ®é‡ï¼ˆå»ºè®®>500æ¡ï¼‰
2. è°ƒæ•´prediction_daysï¼ˆæ¨è3-10å¤©ï¼‰
3. å¯ç”¨use_ensemble=True
4. å°è¯•ä¸åŒçš„model_type

### Q2: å› å­æŒ–æ˜æ²¡æœ‰å‘ç°æœ‰æ•ˆå› å­ï¼Ÿ
**A**:
1. é™ä½min_icé˜ˆå€¼ï¼ˆå¦‚0.01ï¼‰
2. å¢åŠ generationså’Œpopulation_size
3. æ£€æŸ¥æ•°æ®è´¨é‡ï¼Œç¡®ä¿returnsåˆ—æ­£ç¡®

### Q3: æƒ…æ„Ÿåˆ†æå…¨æ˜¯ä¸­æ€§ï¼Ÿ
**A**:
1. å®‰è£…jieba: `pip install jieba`
2. æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ä¸ºä¸­æ–‡
3. ç¡®ä¿æ–‡æœ¬é•¿åº¦è¶³å¤Ÿï¼ˆ>10å­—ï¼‰

### Q4: æ·±åº¦å­¦ä¹ æŠ¥é”™ï¼Ÿ
**A**:
1. å®‰è£…PyTorch: `pip install torch`
2. æ£€æŸ¥æ•°æ®é•¿åº¦ > sequence_length
3. ç¡®ä¿GPUé©±åŠ¨æ­£ç¡®ï¼ˆå¦‚ä½¿ç”¨GPUï¼‰

---

## æŠ€æœ¯æ”¯æŒ

### æ—¥å¿—æŸ¥çœ‹
æ‰€æœ‰æ—¥å¿—ä¿å­˜åœ¨ `logs/` ç›®å½•ï¼š
- `quant_system.log`: ç³»ç»Ÿè¿è¡Œæ—¥å¿—
- åŒ…å«æ¨¡å‹è®­ç»ƒè¿›åº¦ã€é”™è¯¯ä¿¡æ¯ã€æ€§èƒ½æŒ‡æ ‡

### æ¨¡å‹ä¿å­˜
è®­ç»ƒçš„æ¨¡å‹è‡ªåŠ¨ä¿å­˜åœ¨ `data/models/` ç›®å½•ï¼š
- `return_main_YYYYMMDD_HHMMSS.pkl`: æ”¶ç›Šç‡é¢„æµ‹ä¸»æ¨¡å‹
- `direction_main_YYYYMMDD_HHMMSS.pkl`: æ–¹å‘é¢„æµ‹ä¸»æ¨¡å‹

### é‡æ–°è®­ç»ƒæ¨¡å‹
```python
# åˆ é™¤æ—§æ¨¡å‹ï¼Œé‡æ–°è®­ç»ƒ
import os
import shutil
shutil.rmtree('data/models/ml_predictor', ignore_errors=True)

# é‡æ–°è®­ç»ƒ
predictor = ReturnPredictor()
predictor.train(data)
```

---

## æ›´æ–°æ—¥å¿—

### Phase 4 (2025-10-27)
- âœ… æ–°å¢ MLé¢„æµ‹å™¨ï¼ˆæ”¶ç›Šç‡ã€æ–¹å‘ã€æ³¢åŠ¨ç‡ï¼‰
- âœ… æ–°å¢ å› å­æŒ–æ˜ï¼ˆé—ä¼ ç¼–ç¨‹ï¼‰
- âœ… æ–°å¢ æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ˆLSTM/GRU/Transformerï¼‰
- âœ… æ–°å¢ NLPæƒ…æ„Ÿåˆ†æï¼ˆä¸­æ–‡æ”¯æŒï¼‰
- âœ… æ–°å¢ AIé¢„æµ‹UIé¡µé¢
- âœ… æ–°å¢ æƒ…æ„Ÿåˆ†æUIé¡µé¢
- âœ… å®Œå–„ é›†æˆæµ‹è¯•è¦†ç›–

---

## ä¸‹ä¸€æ­¥æ‰©å±•æ–¹å‘

### è®¡åˆ’ä¸­åŠŸèƒ½
1. **å¼ºåŒ–å­¦ä¹ **: è‡ªåŠ¨ç­–ç•¥ä¼˜åŒ–
2. **é›†æˆæ›´å¤šæ•°æ®æº**: è´¢åŠ¡æ•°æ®ã€å®è§‚æ•°æ®
3. **å®æ—¶é¢„è­¦**: Webhooké€šçŸ¥ã€é‚®ä»¶å‘Šè­¦
4. **å¤šèµ„äº§æ”¯æŒ**: æœŸè´§ã€æœŸæƒã€åŠ å¯†è´§å¸
5. **ç»„åˆä¼˜åŒ–**: é©¬ç§‘ç»´èŒ¨ã€Black-Litterman

---

**ç¥æ‚¨æŠ•èµ„é¡ºåˆ©ï¼** ğŸ“ˆâœ¨
